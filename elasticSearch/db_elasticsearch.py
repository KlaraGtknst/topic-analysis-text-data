import collections
from http.client import HTTPException
from elasticsearch import ApiError, ConflictError, Elasticsearch
import base64
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from gensim.utils import simple_preprocess
# own modules
from text_embeddings.preprocessing.read_pdf import *
from user_interface.cli import *
from doc_images.pdf_matrix import *
from elasticSearch.queries.query_documents_tfidf import *
from text_embeddings.universal_sent_encoder_tensorFlow import *
from text_embeddings.hugging_face_sentence_transformer import *
from elasticSearch.queries.query_database import *
from doc_images.PCA.PCA_image_clustering import *
from text_embeddings.TFIDF.preprocessing.TfidfTextPreprocessor import *
from text_embeddings.InferSent.infer_pretrained import *

'''------initiate, fill and search in database-------
run this code by typing and altering the path:
    python3 db_elasticsearch.py -d '/Users/klara/Documents/Uni/bachelorarbeit/data/0/*.pdf' -D '/Users/klara/Documents/Uni/bachelorarbeit/images/images/'
'''

def init_db(client: Elasticsearch, num_dimensions: int, sim_docs_vocab_size: int, n_components: int):
    '''
    :param client: Elasticsearch client
    :param num_dimensions: number of dimensions of the embedding
    :return: None

    This function initializes the database by creating an index (i.e. the structure for an entry of type 'bahamas' database).
    The index contains the following fields:
    - doc2vec: a dense vector of num_dimensions dimensions. This is the vector numerical representation of the document. Its similarity is measured by cosine similarity.
    - text: the text of the document. The text is not tokenized, stemmed etc.
    - path: the path to the document on the local maschine.
    - image: the image of the document (i.e. information about the document layout). The image is encoded in base64 and has 500 dpi.

    cf. https://www.elastic.co/guide/en/elasticsearch/reference/current/binary.html for information about binary for images
    cf. https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html for information about dense vectors and similarity measurement types
    '''
    client.indices.create(index='bahamas', mappings={
        "properties": {
            "doc2vec": {
                "type": "dense_vector",
                "dims": num_dimensions,
                "index": True,
                "similarity": "cosine",
            },
            "google_univ_sent_encoding": {
                "type": "dense_vector",
                "dims": 512,
                "index": True,
                "similarity": "cosine",
            },
            "huggingface_sent_transformer": {
                "type": "dense_vector",
                "dims": 384,
                "index": True,
                "similarity": "cosine",
            },
            "sim_docs_tfidf": {
                "type": "dense_vector",
                "dims": sim_docs_vocab_size + 1, # last cell indicates all-zero-vector-representation
                "index": True,
                "similarity": "cosine",
            },
            "inferSent_AE": {
                "type": "dense_vector",
                "dims": 2048,
                "index": True,
                "similarity": "cosine",
            },
            "pca_image": {
                "type": "dense_vector",
                "dims": n_components,
            },
            "pca_kmeans_cluster": {
                "type": "byte",
            },
            "text": {
                "type": "text",
            },
            "path": {
                "type": "keyword",
            },
            "image": {
                "type": "binary",
            },
        },
    })

def insert_documents(src_paths: list, model: Doc2Vec, client: Elasticsearch, google_model, huggingface_model, sim_doc_tfidf_vectorization: np.ndarray, pca_df: pd.DataFrame, inferEncoder, inferSent_model, image_path: str = None):
    '''
    :param src_paths: path to the documents to be inserted into the database
    :param model: Doc2Vec model
    :param client: Elasticsearch client
    :param google_model: google universal sentence encoder model
    :param huggingface_model: huggingface sentence transformer model
    :param sim_doc_tfidf_vectorization: document-term matrix of the tfidf embedding to find similiar documents
    :param find_doc_tfidf_vectorization: document-term matrix of the tfidf embedding to find a document from the corpus
    :param pca_df: dataframe of the pca weights, clusters generated by KMeans and the corresponding image paths as index
    :param inferEncoder: encoder from trained autoencoder model to reduce dimension of InferSent embedding
    :param inferSent_model: trained InferSent model
    :param image_path: path to the images of the documents to be inserted into the database; if not set, assumes the images are in the same folder as the documents.
    :return: None

    This function inserts the documents into the database 'bahamas'. The documents are inserted as follows:
    - doc2vec: the embedding is inferred from the document text using the trained Doc2Vec model.
        The text is preprocessed using the gensim function 'simple_preprocess', which returns a list of tokens, i.e. unicode strings,
        which are lowercased and tokenized. (cf. https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html).
    - text: the text of the document. The text is not tokenized, stemmed etc.
    - path: the path to the document on the local maschine.
    - image: the image of the document (i.e. information about the document layout). The image is encoded in base64 and has 500 dpi.
    
    The documents receive an id which is the name of the document (i.e. the name of the pdf file without the extension).

    cf. https://stackoverflow.com/questions/8908287/why-do-i-need-b-to-encode-a-string-with-base64 for information about base64 encoding
    cf. https://www.codespeedy.com/convert-image-to-base64-string-in-python/ for information about converting images to base64
    '''
    counter = 0
    image_path = image_path if image_path else (path.split('data/0/')[0] + 'images/images/')

    for i in range(len(src_paths)):
        path = src_paths[i]
        try:
            id = path.split('/')[-1].split('.')[0]  # document title
            image = image_path + id  + '.png'
            try:
                with open(image, "rb") as img_file:
                    b64_image = base64.b64encode(img_file.read())
            except FileNotFoundError:
                # bc i did not copy all images from cluster to local machine
                # dummy (black) picture to avoid not inserting the document into the database
                b64_image = base64.b64encode(np.zeros([100,100,3],dtype=np.uint8)) # TODO: or insert None

            try:
                text = pdf_to_str(path)
            except:
                # missing EOF marker in pdf
                print(f'EOF marker missing in {path}.')
                print(pdf_to_str(path))
            

            pca_df_row = pca_df.loc[pca_df.index == image] if image in list(pca_df.index) else None

            # InferSent embedding
            inferSent_embedding = inferSent_model.encode([text, text], tokenize=True)
            compressed_infersent_embedding = inferEncoder.predict(x=inferSent_embedding)[0]

            try:
                client.create(index='bahamas', id=id, document={
                    "doc2vec": model.infer_vector(simple_preprocess(pdf_to_str(path))),
                    "sim_docs_tfidf": np.ravel(np.array(sim_doc_tfidf_vectorization[i])),
                    "google_univ_sent_encoding": embed([text], google_model).numpy().tolist()[0],
                    "huggingface_sent_transformer": huggingface_model.encode(text),
                    "inferSent_AE": compressed_infersent_embedding,
                    "pca_image": pca_df_row['pca_weights'].item() if pca_df_row is not None else None,
                    "pca_kmeans_cluster": pca_df_row['cluster'] if pca_df_row is not None else None,
                    "text": text,
                    "path": path,
                    "image": str(b64_image) # TODO: statt str... b46_image.decode('ASCII'),
                })
            except ApiError as err:
                counter += 1
        except ConflictError as err:
            continue
    if counter > 0:
        print(f'{counter} from {len(src_paths)} documents raised an ApiError error and are thus, not inserted into the database.')



def get_tagged_input_documents(src_paths: list, tokens_only: bool = False):
    '''
    :param src_paths: list of paths to the documents to be inserted into the database
    :param tokens_only: if True, only the tokens of the document are returned, else tagged tokens are returned
    :return: tagged tokens or only the tokens (depending on tokens_only)

    The gensim function 'simple_preprocess' converts a document into a list of tokens (cf. https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html).
    The resulting list of unicode strings is lowercased and tokenized.

    cf. https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py
    for the original code
    '''
    for i in range(len(src_paths)):
        path = src_paths[i]
        tokens = simple_preprocess(pdf_to_str(path))
        if tokens_only:
            yield tokens
        else:
            yield TaggedDocument(tokens, [i])
   



def assess_model(model: Doc2Vec, train_corpus: list):
    '''
    :param model: trained Doc2Vec model
    :param train_corpus: list of tagged documents
    :return: None

    This function assesses by:
    (1) infer a vector of a document from the training corpus
    (2) compare inferred vector with the vector of the document in the training corpus
    (3) return rank of the document based on self-similarity (i.e. the document itself should be ranked first)
    '''
    print('-'*100)
    ranks = []  # list of ranks the documents got when compared to themselves
    second_ranks = []   # list of similarities of the second most similar document
    for doc_id in range(len(train_corpus)):
        inferred_vector = model.infer_vector(train_corpus[doc_id].words)
        sims = model.dv.most_similar([inferred_vector], topn=len(model.dv)) # topn: number of most similar documents to be returned
        rank = [docid for docid, sim in sims].index(doc_id) # rank of the document via id
        ranks.append(rank)  # saves the rank of the document in terms of self-similarity
        second_ranks.append(sims[1])    # saves the similarity of the second most similar document

        print('Document ({}): «{}»\n'.format(doc_id, ' '.join(train_corpus[doc_id].words[:10])))
        print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\n' % model)
        for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:
            print(u'%s %s: «%s»\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words[:10])))
        print('-'*80)
    counter = collections.Counter(ranks)
    print(f'{counter[0]} documents are most self-similar to themselves.\n{counter[1]} documents were not ranked first.')
    

def infer_embedding_for_single_document(model: Doc2Vec, text: str):
    '''
    :param model: trained Doc2Vec model
    :param text: text of the document to be embedded
    :return: embedding vector of the document

    This function infers the embedding vector of a document.
    '''
    vector = model.infer_vector(simple_preprocess(text))
    return vector

def tfidf_aux(src_paths: list) -> tuple:
    '''
    :param src_paths: paths to the documents to be inserted into the database
    :return: document-term matrix with a all-zero-flag-cell at the end and the trained tfidf vectorizer model
    '''
    docs = get_docs_from_file_paths(src_paths)
    # usage of custom preprocessor
    sim_docs_tfidf = TfidfVectorizer(input='content', preprocessor=TfidfTextPreprocessor().fit_transform, min_df=3, max_df=int(len(docs)*0.07))
    sim_docs_document_term_matrix = sim_docs_tfidf.fit_transform(docs).todense()

    # add flags, which indicate if the document is represented by an all zero vector
    flags = np.array([1 if np.array([entry  == 0 for entry in sim_docs_document_term_matrix[i]]).all() else 0 for i in range(len(sim_docs_document_term_matrix))]).reshape(len(sim_docs_document_term_matrix),1)
    flag_matrix = np.append(sim_docs_document_term_matrix, flags, axis=1)

    return flag_matrix, sim_docs_tfidf


def show_best_search_results(scores, src_paths, image_src_path=None):
    # create image matrix of 9 most similar images for query image
    image_paths = [image_src_path + id.split('.')[0]  + '.png' if image_src_path else src_paths.split('.')[0] + '.png' for id in scores.values()]
    create_image_matrix(input_files=image_paths, dim=3, output_path=None)

def main(src_paths, image_src_path):
    
    NUM_DIMENSIONS = 55
    NUM_COMPONENTS = 2

    print('-' * 80)

    # InferSent embedding
    MODEL_PATH = '/Users/klara/Developer/Uni/encoder/infersent1.pkl'
    W2V_PATH = '/Users/klara/Developer/Uni/GloVe/glove.840B.300d.txt'
    infersent, docs = init_infer(model_path=MODEL_PATH, w2v_path=W2V_PATH, file_paths=src_paths, version=1)
    infer_embeddings = infersent.encode(docs, tokenize=True)
    encoded_infersent_embedding, ae_infer_encoder = autoencoder_emb_model(input_shape=infer_embeddings.shape[1], latent_dim=2048, data=infer_embeddings)


    # tfidf embedding incl. all-zero-vector-flag
    tfidf_matrix, sim_docs_tfidf = tfidf_aux(src_paths)
    sim_docs_vocab_size = len(list(sim_docs_tfidf.vocabulary_.values()))
    #print(f'Vocabulary size (sim): {sim_docs_vocab_size}')

    # huggingface sentence transformer
    huggingface_model = init_hf_sentTrans_model()

    # google universal sentence encoder
    google_model = google_univ_sent_encoding_aux()

    # Create the client instance
    client = Elasticsearch("http://localhost:9200")
    client.options(ignore_status=[400,404]).indices.delete(index='bahamas')

    # delete old index and create new one
    if ('bahamas' not in client.indices.get_alias(index='*')) or (client.indices.get_mapping(index='bahamas')['bahamas']['mappings']['properties']['doc2vec']['dims'] != NUM_DIMENSIONS):
        client.options(ignore_status=[400,404]).indices.delete(index='bahamas')
        init_db(client, num_dimensions=NUM_DIMENSIONS, sim_docs_vocab_size=sim_docs_vocab_size, n_components=NUM_COMPONENTS)
    
    # training corpus
    train_corpus = list(get_tagged_input_documents(src_paths))

    # doc2vec model 
    # infrequent words are discarded, since retaining them can make model worse
    # iteration for 10s-of-thousands of documents: 10-20; more for smaller datasets
    doc2vec_model = Doc2Vec(train_corpus, vector_size=NUM_DIMENSIONS, window=2, min_count=2, workers=4, epochs=40)

    # build a vocabulary (i.e. list of unique words); accessable via model.wv.index_to_key
    doc2vec_model.build_vocab(train_corpus, update=True)

    # train the model
    doc2vec_model.train(train_corpus, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)

    # assess the model
    # here: using training corpus -> overfitting, not representative
    #assess_model(doc2vec_model, train_corpus)

    # PCA + KMeans clustering
    pca_cluster_df = get_cluster_PCA_df(src_path= image_src_path, n_cluster= 4, n_components= NUM_COMPONENTS, preprocess_image_size=600)

    # insert documents into database
    insert_documents(src_paths, doc2vec_model, client, image_path=image_src_path, google_model=google_model, huggingface_model=huggingface_model, sim_doc_tfidf_vectorization=tfidf_matrix, pca_df=pca_cluster_df, inferSent_model=infersent, inferEncoder=ae_infer_encoder)

    # alternatively, use AsyncElasticsearch or time.sleep(1)
    client.indices.refresh(index="bahamas")
    
    

    # sample query for a document
    '''path = src_paths[50]
    print('\n' + '-' * 40, path, '-' * 40)
    scores = search_sim_doc2vec_docs_in_db(client, doc2vec_model, path)
    for score in list(scores.keys()):
        print(score, scores[score])

    # create image matrix of 9 most similar images for query image
    show_best_search_results(scores, src_paths, image_src_path)'''


    # properties in db
    print(client.indices.get_mapping(index='bahamas'))

    # number of documents in database
    client.indices.refresh(index='bahamas')
    resp = client.count(index='bahamas')
    print('number of documents in database: ', resp['count'])