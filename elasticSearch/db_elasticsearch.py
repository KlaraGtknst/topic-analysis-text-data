import collections
from http.client import HTTPException
from elasticsearch import ApiError, ConflictError, Elasticsearch
import base64
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from gensim.utils import simple_preprocess
# own modules
from text_embeddings.preprocessing.read_pdf import *
from user_interface.cli import *
from doc_images.pdf_matrix import *
from elasticSearch.queries.query_documents_tfidf import *
from text_embeddings.universal_sent_encoder_tensorFlow import *
from text_embeddings.hugging_face_sentence_transformer import *
from elasticSearch.queries.query_database import *
from doc_images.PCA.PCA_image_clustering import *

'''------initiate, fill and search in database-------
run this code by typing and altering the path:
    python3 db_elasticsearch.py -d '/Users/klara/Documents/Uni/bachelorarbeit/data/0/*.pdf' -D '/Users/klara/Documents/Uni/bachelorarbeit/images/images/'
'''

def init_db(client: Elasticsearch, num_dimensions: int, sim_docs_vocab_size: int, n_components: int):
    '''
    :param client: Elasticsearch client
    :param num_dimensions: number of dimensions of the embedding
    :return: None

    This function initializes the database by creating an index (i.e. the structure for an entry of type 'bahamas' database).
    The index contains the following fields:
    - embedding: a dense vector of num_dimensions dimensions. This is the vector numerical representation of the document. Its similarity is measured by cosine similarity.
    - text: the text of the document. The text is not tokenized, stemmed etc.
    - path: the path to the document on the local maschine.
    - image: the image of the document (i.e. information about the document layout). The image is encoded in base64 and has 500 dpi.

    cf. https://www.elastic.co/guide/en/elasticsearch/reference/current/binary.html for information about binary for images
    cf. https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html for information about dense vectors and similarity measurement types
    '''
    client.indices.create(index='bahamas', mappings={
        "properties": {
            "embedding": {
                "type": "dense_vector",
                "dims": num_dimensions,
                "index": True,
                "similarity": "cosine",
            },
            "google_univ_sent_encoding": {
                "type": "dense_vector",
                "dims": 512,
                "index": True,
                "similarity": "cosine",
            },
            "huggingface_sent_transformer": {
                "type": "dense_vector",
                "dims": 384,
                "index": True,
                "similarity": "cosine",
            },
            # TODO: vector size +1, flag 1 if zero vector
            "sim_docs_tfidf": {
                "type": "dense_vector",
                "dims": sim_docs_vocab_size, #FIXME: uses 2048 as maximum, bc vocab_size is 7243
                "index": True,
                "similarity": "cosine",
            },
            '''"find_doc_tfidf": {
                "type": "dense_vector",
                "dims": find_doc_vocab_size, #FIXME: uses 2048 as maximum, bc vocab_size is 7243
                "index": True,
                "similarity": "cosine",
            },'''
            "pca_image": {
                "type": "dense_vector",
                "dims": n_components,
                #"index": True,
                #"similarity": "cosine",
                #"store": True,
            },
            "pca_kmeans_cluster": {
                "type": "byte",
                #"index": True,
                #"similarity": "boolean",
                #"store": True,
            },
            "text": {
                "type": "text",
            },
            "path": {
                "type": "keyword",
            },
            "image": {
                "type": "binary",
            },
        },
    })

def insert_documents(src_paths: list, model: Doc2Vec, client: Elasticsearch, google_model, huggingface_model, sim_doc_tfidf_vectorization: np.ndarray, pca_df: pd.DataFrame, image_path: str = None): #find_doc_tfidf_vectorization: np.ndarray
    '''
    :param src_paths: path to the documents to be inserted into the database
    :param model: Doc2Vec model
    :param client: Elasticsearch client
    :param google_model: google universal sentence encoder model
    :param huggingface_model: huggingface sentence transformer model
    :param sim_doc_tfidf_vectorization: document-term matrix of the tfidf embedding to find similiar documents
    :param find_doc_tfidf_vectorization: document-term matrix of the tfidf embedding to find a document from the corpus
    :param pca_df: dataframe of the pca weights, clusters generated by KMeans and the corresponding image paths as index
    :param image_path: path to the images of the documents to be inserted into the database; if not set, assumes the images are in the same folder as the documents.
    :return: None

    This function inserts the documents into the database 'bahamas'. The documents are inserted as follows:
    - embedding: the embedding is inferred from the document text using the trained Doc2Vec model.
        The text is preprocessed using the gensim function 'simple_preprocess', which returns a list of tokens, i.e. unicode strings,
        which are lowercased and tokenized. (cf. https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html).
    - text: the text of the document. The text is not tokenized, stemmed etc.
    - path: the path to the document on the local maschine.
    - image: the image of the document (i.e. information about the document layout). The image is encoded in base64 and has 500 dpi.
    
    The documents receive an id which is the name of the document (i.e. the name of the pdf file without the extension).

    cf. https://stackoverflow.com/questions/8908287/why-do-i-need-b-to-encode-a-string-with-base64 for information about base64 encoding
    cf. https://www.codespeedy.com/convert-image-to-base64-string-in-python/ for information about converting images to base64
    '''
    counter = 0
    for i in range(len(src_paths)):
        path = src_paths[i]
        try:
            id = path.split('/')[-1].split('.')[0]  # document title
            image = image_path + id  + '.png' if image_path else path.split('.')[0] + '.png'
            try:
                with open(image, "rb") as img_file:
                    b64_image = base64.b64encode(img_file.read())
            except FileNotFoundError:
                # bc i did not copy all images from cluster to local machine
                # dummy (black) picture to avoid not inserting the document into the database
                b64_image = base64.b64encode(np.zeros([100,100,3],dtype=np.uint8)) # TODO: or insert None

            try:
                text = pdf_to_str(path)
            except:
                # missing EOF marker in pdf
                print(f'EOF marker missing in {path}.')
                print(pdf_to_str(path))
            
            pca_df_row = pca_df.loc[pca_df.index == image]

            #print(doc_tfidf_vectorization[i].shape)
            try:
                client.create(index='bahamas', id=id, document={
                    "embedding": model.infer_vector(simple_preprocess(pdf_to_str(path))),
                    # some documents have no words in the vocabulary, i.e. the document-term matrix is a zero matrix -> insert None to avoid error and thus, them not being inserted into the database
                    # TODO: vector size +1, flag 1 if zero vector
                    "sim_docs_tfidf": None if np.array([entry  == 0 for entry in sim_doc_tfidf_vectorization[i]]).all() else np.ravel(np.array(sim_doc_tfidf_vectorization[i])),
                    #"find_doc_tfidf": find_doc_tfidf_vectorization[i], too big!
                    "google_univ_sent_encoding": embed([text], google_model).numpy().tolist()[0],
                    "huggingface_sent_transformer": huggingface_model.encode(text),
                    "pca_image": pca_df_row['pca_weights'].values,
                    "pca_kmeans_cluster": pca_df_row['cluster'],
                    "text": text,
                    "path": path,
                    "image": str(b64_image),
                })
            except ApiError as err:
                counter += 1
        except ConflictError as err:
            continue
    if counter > 0:
        print(f'{counter} from {len(src_paths)} documents raised an ApiError error and are thus, not inserted into the database.')



def get_tagged_input_documents(src_paths: list, tokens_only: bool = False):
    '''
    :param src_paths: list of paths to the documents to be inserted into the database
    :param tokens_only: if True, only the tokens of the document are returned, else tagged tokens are returned
    :return: tagged tokens or only the tokens (depending on tokens_only)

    The gensim function 'simple_preprocess' converts a document into a list of tokens (cf. https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html).
    The resulting list of unicode strings is lowercased and tokenized.

    cf. https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py
    for the original code
    '''
    for i in range(len(src_paths)):
        path = src_paths[i]
        tokens = simple_preprocess(pdf_to_str(path))
        if tokens_only:
            yield tokens
        else:
            yield TaggedDocument(tokens, [i])
   



def assess_model(model: Doc2Vec, train_corpus: list):
    '''
    :param model: trained Doc2Vec model
    :param train_corpus: list of tagged documents
    :return: None

    This function assesses by:
    (1) infer a vector of a document from the training corpus
    (2) compare inferred vector with the vector of the document in the training corpus
    (3) return rank of the document based on self-similarity (i.e. the document itself should be ranked first)
    '''
    print('-'*100)
    ranks = []  # list of ranks the documents got when compared to themselves
    second_ranks = []   # list of similarities of the second most similar document
    for doc_id in range(len(train_corpus)):
        inferred_vector = model.infer_vector(train_corpus[doc_id].words)
        sims = model.dv.most_similar([inferred_vector], topn=len(model.dv)) # topn: number of most similar documents to be returned
        rank = [docid for docid, sim in sims].index(doc_id) # rank of the document via id
        ranks.append(rank)  # saves the rank of the document in terms of self-similarity
        second_ranks.append(sims[1])    # saves the similarity of the second most similar document

        print('Document ({}): «{}»\n'.format(doc_id, ' '.join(train_corpus[doc_id].words[:10])))
        print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\n' % model)
        for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:
            print(u'%s %s: «%s»\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words[:10])))
        print('-'*80)
    counter = collections.Counter(ranks)
    print(f'{counter[0]} documents are most self-similar to themselves.\n{counter[1]} documents were not ranked first.')
    

def infer_embedding_for_single_document(model: Doc2Vec, text: str):
    '''
    :param model: trained Doc2Vec model
    :param text: text of the document to be embedded
    :return: embedding vector of the document

    This function infers the embedding vector of a document.
    '''
    vector = model.infer_vector(simple_preprocess(text))
    return vector

def tfidf_aux(src_paths: list) -> tuple:
    '''
    :param src_paths: paths to the documents to be inserted into the database
    :return: document-term matrix and the trained tfidf vectorizer model
    '''
    docs = get_docs_from_file_paths(src_paths)
    # reduce dimensionality of tfidf matrix by allowing only words that appear a certain number of times
    # (1) tfidf embedding to find similiar documents (i.e. words have to appear in more than one document)
    # to reduce dimensionality, only words that appear in more than 3 and less than 4% of the documents are considered
    # FIXME: many/ 2 document have none of the words in the vocabulary, i.e. the document-term matrix is a zero matrix
    # no more numbers in vocabulary, only words, cf. https://stackoverflow.com/questions/51643427/how-to-make-tfidfvectorizer-only-learn-alphabetical-characters-as-part-of-the-vo
    # usage of uni-grams only
    sim_docs_tfidf = TfidfVectorizer(input='content', lowercase=True, min_df=3, max_df=int(len(docs)*0.07), analyzer='word', stop_words='english', token_pattern=r'(?u)\b[A-Za-z]+\b', strip_accents='ascii')
    # to dense: https://hackernoon.com/document-term-matrix-in-nlp-count-and-tf-idf-scores-explained
    sim_docs_document_term_matrix = sim_docs_tfidf.fit_transform(docs).todense()

    # (2) tfidf embedding to find a document from the corpus (i.e. words appearing in many documents are not informative)
    # 3762 is too big for maximum dimension of elastic search
    '''find_doc_tfidf = TfidfVectorizer(input='content', lowercase=True, max_df=1, analyzer='word', stop_words='english', token_pattern="\w+")
    find_doc_document_term_matrix = find_doc_tfidf.fit_transform(docs)
    find_doc_D = get_tfidf_matrix(src_paths, find_doc_tfidf, find_doc_document_term_matrix)'''
    return sim_docs_document_term_matrix, sim_docs_tfidf #find_doc_D, find_doc_tfidf, 

def google_univ_sent_encoding_aux():
    '''
    :param src_paths: paths to the documents to be inserted into the database
    :return: document-term matrix and the trained tfidf vectorizer model
    '''
    try:
        module_url = "https://tfhub.dev/google/universal-sentence-encoder/4"
        model = hub.load(module_url)
    except:
        module_url = "https://tfhub.dev/google/universal-sentence-encoder-large/5"
        model = hub.load(module_url)
    return model


def show_best_search_results(scores, src_paths, image_src_path=None):
    # create image matrix of 9 most similar images for query image
    image_paths = [image_src_path + id.split('.')[0]  + '.png' if image_src_path else src_paths.split('.')[0] + '.png' for id in scores.values()]
    create_image_matrix(input_files=image_paths, dim=3, output_path=None)

if __name__ == '__main__':
    args = arguments()
    src_paths = get_input_filepath(args)
    image_src_path = get_filepath(args, option='image')
    
    NUM_DIMENSIONS = 55
    NUM_COMPONENTS = 2

    print('-' * 80)

    # tfidf 
    # TODO: how to find out which document belongs to a row (first/ only index)?
    # FIXME: vocab size to big for maximum dimension of elastic search
    #find_doc_D, find_doc_tfidf, 
    sim_docs_D, sim_docs_tfidf = tfidf_aux(src_paths)
    sim_docs_vocab_size = len(list(sim_docs_tfidf.vocabulary_.values()))
    #find_doc_vocab_size =  len(list(find_doc_tfidf.vocabulary_.values()))
    print(f'Vocabulary size (sim): {sim_docs_vocab_size}')#\nVocabulary size (find): {find_doc_vocab_size}')
    #print(doc_tfidf_vectorization.shape)

    # huggingface sentence transformer
    huggingface_model = init_hf_sentTrans_model()
    #huggingface_embedding = huggingface_model.encode(src_paths)

    # google universal sentence encoder
    google_model = google_univ_sent_encoding_aux()

    # Create the client instance
    client = Elasticsearch("http://localhost:9200")
    client.options(ignore_status=[400,404]).indices.delete(index='bahamas')

    # delete old index and create new one
    if ('bahamas' not in client.indices.get_alias(index='*')) or (client.indices.get_mapping(index='bahamas')['bahamas']['mappings']['properties']['embedding']['dims'] != NUM_DIMENSIONS):
        client.options(ignore_status=[400,404]).indices.delete(index='bahamas')
        init_db(client, num_dimensions=NUM_DIMENSIONS, sim_docs_vocab_size=sim_docs_vocab_size, n_components=NUM_COMPONENTS)
    
    # training corpus
    train_corpus = list(get_tagged_input_documents(src_paths))

    # model 
    # infrequent words are discarded, since retaining them can make model worse
    # iteration for 10s-of-thousands of documents: 10-20; more for smaller datasets
    model = Doc2Vec(train_corpus, vector_size=NUM_DIMENSIONS, window=2, min_count=2, workers=4, epochs=40)

    # build a vocabulary (i.e. list of unique words); accessable via model.wv.index_to_key
    model.build_vocab(train_corpus, update=True)

    # additonal information about each word
    # word = 'credit'
    # print(f"Word '{word}' appeared {model.wv.get_vecattr(word, 'count')} times in the training corpus.")

    # train the model
    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)

    # infer a vector of a new document
    #print(f'This is the numerical representation of the document: \n{infer_embedding_for_single_document(model, text="This is a new document to be searched for.")}')
    
    # assess the model
    # here: using training corpus -> overfitting, not representative
    #assess_model(model, train_corpus)

    pca_cluster_df = get_cluster_PCA_df(src_path= image_src_path, n_cluster= 4, n_components= NUM_COMPONENTS, preprocess_image_size=600)

    
    insert_documents(src_paths, model, client, image_path=image_src_path, google_model=google_model, huggingface_model=huggingface_model, sim_doc_tfidf_vectorization=sim_docs_D, pca_df=pca_cluster_df)  #find_doc_tfidf_vectorization=find_doc_D

    # alternatively, use AsyncElasticsearch or time.sleep(1)
    client.indices.refresh(index="bahamas")
    
    

    # sample query for a document
    '''path = src_paths[50]
    print('\n' + '-' * 40, path, '-' * 40)
    scores = search_in_db(client, model, path)
    for score in list(scores.keys()):
        print(score, scores[score])

    # create image matrix of 9 most similar images for query image
    show_best_search_results(scores, src_paths, image_src_path)'''

    # FIXME: TypeError(f"Unable to serialize {data!r} (type: {type(data)})") TypeError: Unable to serialize DenseVector([...
    #print('\n' 'TFIDF:\n', '-' * 40, path, '-' * 40)
    '''scores = find_document_tfidf(client, find_doc_tfidf, path)
    for score in list(scores.keys()):
        print(score, scores[score])

    # create image matrix of 9 most similar images for query image
    show_best_search_results(scores, src_paths, image_src_path)'''

    print(client.indices.get_mapping(index='bahamas'))

    client.indices.refresh(index='bahamas')
    resp = client.count(index='bahamas')
    print('number of documents in database: ', resp['count'])